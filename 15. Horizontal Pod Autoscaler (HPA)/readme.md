# ðŸš€ **Lesson 17: Horizontal Pod Autoscaler (HPA)**

> In simple words â€” Kubernetes can **automatically increase or decrease the number of Pods** based on load.

---

## ðŸŽ¯ Goal of This Lesson

After this lesson, youâ€™ll learn ðŸ‘‡

- What HPA is and why itâ€™s needed
- How it works
- How to scale Pods based on CPU usage
- A real live example

---

## ðŸ§  Easy Understanding

Imagine you have a website â€”
In the daytime, you have **100 visitors**, but at night you get **10,000 visitors**! ðŸ˜…

If you always run **10 Pods**, you waste resources during the day.
But if you run only **2 Pods**, your site may crash at night!

ðŸ‘‰ Thatâ€™s why we need something that can:
**Add Pods when load increases, and remove Pods when load decreases.**

Thatâ€™s exactly what **Horizontal Pod Autoscaler (HPA)** does âœ…

---

## âš™ï¸ What Does HPA Do?

**HPA** watches your Deployment or ReplicaSet.
It checks CPU (or memory) usage and changes the number of Pods automatically.

ðŸ“Œ Simple logic:

- If CPU usage > 70% â†’ add more Pods
- If CPU usage < 40% â†’ remove some Pods

---

## âš™ï¸ How HPA Works

1. **Metrics Server** collects CPU and memory usage.
2. **HPA Controller** checks that data.
3. **Deployment** increases or decreases Pods based on it.

ðŸ§© Flow Diagram:

```
CPU usage â†‘ â†’ HPA checks â†’ add pods
CPU usage â†“ â†’ HPA checks â†’ remove pods
```

---

## ðŸ”§ Example: Create an HPA

### Step 0ï¸âƒ£ â€” Make sure Metrics Server is installed

Check it:

```bash
kubectl get deployment metrics-server -n kube-system
```

If not found, install it:

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

---

### Step 1ï¸âƒ£ â€” Create a Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hpa-demo
  template:
    metadata:
      labels:
        app: hpa-demo
    spec:
      containers:
        - name: hpa-demo-container
          image: nginx
          resources:
            requests:
              cpu: "100m"
            limits:
              cpu: "200m"
```

Save it as **`hpa-deploy.yaml`**
Then apply it ðŸ‘‡

```bash
kubectl apply -f hpa-deploy.yaml
```

---

### Step 2ï¸âƒ£ â€” Create the HPA

```bash
kubectl autoscale deployment hpa-demo --cpu-percent=50 --min=1 --max=5
```

ðŸ”¹ `--cpu-percent=50` â†’ When CPU usage crosses 50%, create new Pods
ðŸ”¹ `--min=1` â†’ Minimum 1 Pod
ðŸ”¹ `--max=5` â†’ Maximum 5 Pods

---

### Step 3ï¸âƒ£ â€” Check the Status

```bash
kubectl get hpa
```

Example output:

```
NAME        REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo    Deployment/hpa-demo    20%/50%   1         5         1          2m
```

When CPU usage goes up â†’ HPA increases Pods automatically.

---

### Step 4ï¸âƒ£ â€” Test the Scaling (Optional)

Run a load generator Pod:

```bash
kubectl run -i --tty load-generator --image=busybox /bin/sh
```

Then inside it, run a continuous loop:

```bash
while true; do wget -q -O- http://hpa-demo; done
```

This increases CPU usage â†’ and HPA automatically adds more Pods ðŸ˜Ž

---

## ðŸ§© Real-Life Example

Imagine you have an **e-commerce app**:

- Morning â†’ few orders â†’ 2 Pods
- Afternoon â†’ heavy traffic â†’ 6 Pods
- Night â†’ few users â†’ 2 Pods again

You donâ€™t need to change anything â€”
**Kubernetes auto-scales for you!**
ðŸ’¡ This saves cost and improves performance.

---

## âœ… Summary

| Concept            | Description                                   |
| ------------------ | --------------------------------------------- |
| **HPA**            | Automatically changes Pod count based on load |
| **Metrics Server** | Provides CPU/Memory data                      |
| **Min/Max Pods**   | Sets allowed Pod range                        |
| **Target CPU %**   | Decides when scaling happens                  |

---

## ðŸ§© Assignment

1ï¸âƒ£ Create a new Deployment (use `nginx`).
2ï¸âƒ£ Run this command ðŸ‘‡

```bash
kubectl autoscale deployment nginx --cpu-percent=60 --min=1 --max=4
```

3ï¸âƒ£ Then check HPA status:

```bash
kubectl get hpa
```

4ï¸âƒ£ Try a load test to watch Pods automatically scale up/down.

---

Great job again Juboraj! ðŸ’ª
Next, weâ€™ll learn **Lesson 18: Kubernetes Taints & Tolerations** â€”
It controls **which Pod runs on which Node** (for better scheduling).

ðŸ‘‰ Shall I start **Lesson 18** now?
